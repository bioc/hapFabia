\name{iterateSegments}

\alias{iterateSegments}

\title{Loop over DNA segments with a call of \code{hapFabia}}

\description{

  \code{iterateSegments}: \R implementation of \code{iterateSegments}.

  Loops over all segments and calls \code{hapFabia} and then stores the
  results. Segments have been
  generated by \code{split_sparse_matrix}.


}
\usage{

iterateSegments(startRun=1,endRun,shift=5000,segmentSize=10000,
   annotationFile=NULL,fileName,prefixPath="",
   sparseMatrixPostfix="_mat",annotPostfix="_annot.txt",
   individualsPostfix="_individuals.txt",individuals=0,
   lowerBP=0,upperBP=0.05,p=10,iter=40,quant=0.01,eps=1e-5,
   alpha=0.03,cyc=50,non_negative=1,write_file=0,norm=0,
   lap=100.0,haploClusterLength=50,Lt = 0.1,Zt = 0.2,
   thresCount=1e-5,mintagSNVsFactor=3/4,pMAF=0.03,
   haplotypes=FALSE,cut=0.8,procMinIndivids=0.1,thresPrune=1e-3,
   simv="minD",minTagSNVs=6,minIndivid=2,avSNVsDist=100,SNVclusterLength=100)

}
\arguments{
 \item{startRun}{first segment.}
 \item{endRun}{last segment.}
 \item{shift}{distance between starts of adjacent segments.}
 \item{segmentSize}{number of SNVs in a segment.}
 \item{annotationFile}{file name of the annotation file for the individuals.}
 \item{fileName}{passed to hapFabia: file name of the genotype matrix in sparse format.}
 \item{prefixPath}{passed to hapFabia: path to the genotype file.}
 \item{sparseMatrixPostfix}{passed to hapFabia: postfix string for the sparse matrix.}
 \item{annotPostfix}{passed to hapFabia: postfix string for the SNV annotation file.}
 \item{individualsPostfix}{passed to hapFabia: postfix string for the
   file containing the names of the individuals.}
 \item{individuals}{passed to hapFabia: vector of individuals which are included into the analysis; default = 0 (all individuals).}
 \item{lowerBP}{passed to hapFabia: lower bound on minor allele frequencies (MAF); however at least two occurrences are required to remove private SNVs.}
 \item{upperBP}{passed to hapFabia: upper bound  on minor allele frequencies (MAF) to extract rare variants.}
 \item{p}{passed to hapFabia: number of biclusters per iteration.}
 \item{iter}{passed to hapFabia: number of iterations.}
 \item{quant}{passed to hapFabia: percentage of loadings L to remove in each iteration.}
 \item{eps}{passed to hapFabia: lower bound for variational parameter lapla; default 1e-5.}
 \item{alpha}{passed to hapFabia: sparseness of the loadings; default = 0.03.}
 \item{cyc}{passed to hapFabia: number of cycles per iterations; default 50.}
 \item{non_negative}{passed to hapFabia: non-negative factors and loadings if non_negative = 1; default = 1 (yes).}
 \item{write_file}{passed to hapFabia: results are written to files (L in sparse format), default = 0 (not written).}
 \item{norm}{passed to hapFabia: data normalization; default 1 (no normalization).}
 \item{lap}{passed to hapFabia: minimal value of the variational parameter; default 100.0.}
 \item{haploClusterLength}{passed to hapFabia: typical haplotype cluster length in kbp.}
 \item{Lt}{passed to hapFabia: percentage of largest Ls to consider for haplotype cluster extraction.}
 \item{Zt}{passed to hapFabia: percentage of largest Zs to consider for haplotype cluster extraction.}
 \item{thresCount}{passed to hapFabia: p-value of random histogram hit; default 1e-5.}
 \item{mintagSNVsFactor}{passed to hapFabia: percentage of haplotype cluster overlap; default 3/4.}
 \item{pMAF}{passed to hapFabia: averaged and corrected (for non-uniform distributions) minor allele frequency.}
\item{haplotypes}{passed to hapFabia: haplotypes = TRUE then phased genotypes meaning two chromosomes per individual otherwise unphased genotypes.}
\item{cut}{passed to hapFabia: cutoff for merging haplotype clusters after a hierarchical
 clustering; default 0.8.}
\item{procMinIndivids}{passed to hapFabia: percentage of cluster individuals a tagSNV must
 tag to be considered as tagSNV for the haplotype cluster.}
\item{thresPrune}{passed to hapFabia: threshold for pruning border tagSNVs based on an
 exponential distribution where border tagSNVs with large distances to
 the next tagSNV are pruned.}
\item{simv}{passed to hapFabia: similarity measure for merging clusters: \code{"minD"} (percentage of smaller explained by larger set),
   \code{"jaccard"} (Jaccard index), \code{"dice"} (Dice index), or
   \code{"maxD"}; default \code{"minD"}.}
\item{minTagSNVs}{passed to hapFabia: minimum matching tagSNVs for cluster similarity;
 otherwise the similarity is set to zero.}
\item{minIndivid}{passed to hapFabia: minimum matching individuals for cluster similarity;
 otherwise the similarity is set to zero.}
 \item{avSNVsDist}{passed to hapFabia: average distance between SNVs in
   base pairs - used
 together with \code{haploClusterLength} to compute the number of SNVs
 in the histogram bins; default=100 (from the
 1000GenomesProject).}
\item{SNVclusterLength}{passed to hapFabia: if \code{haploClusterLength=0} then the number
 of SNVs in the histogram bins can be given directly; default 100.}


}
\details{


  Implementation in \R.
  Reads annotation of the samples if available,
  then calls \code{hapFabia} and stores its results.
  Results are saved in EXCEL format and as \R
  binaries.

 Annotation file \code{..._annot.txt} for SNVs:
\enumerate{
 \item  first line: number individuals;
 \item  second line: number SNVs;
 \item  for each SNV a line containing following field that are blank separated:
 "chromosome", "physical position", "snvNames", "snvMajor", "snvMinor",
 "quality", "pass", "info of vcf file", "fields in vcf file",
 "frequency", "0/1: 1 is changed if major allele is actually minor
 allele".
 }
 
 The annotation file for individuals,
  which name is give to \code{annotationFile},
 contains per individual a tab separated line with
 \enumerate{
   \item id;
   \item subPopulation;
   \item population;
   \item platform.
 }
 
}
\seealso{
\code{\link{HaploCluster-class}},
\code{\link{HaploClusterList-class}},
\code{\link{analyzeHaploClusters}},
\code{\link{compareHaploClusterLists}},
\code{\link{extractHaploClusters}},
\code{\link{findDenseRegions}},
\code{\link{hapFabia}},
\code{\link{hapFabiaVersion}},
\code{\link{hapRes}},
\code{\link{chr1ASW1000G}},
\code{\link{haploClusterList2excel}},
\code{\link{identifyDuplicates}},
\code{\link{iterateSegments}},
\code{\link{makePipelineFile}},
\code{\link{matrixPlot}},
\code{\link{mergeHaploClusterLists}},
\code{\link{mergedHaploClusterList}},
\code{\link{plotHaplotypeCluster}},
\code{\link{res}},
\code{\link{setAnnotation}},
\code{\link{setStatistics}},
\code{\link{sim}},
\code{\link{simu}},
\code{\link{simulateHaploClustersFabia}},
\code{\link{simulateHaplotypeClusters}},
\code{\link{split_sparse_matrix}},
\code{\link{toolsFactorizationClass}},
\code{\link{vcftoFABIA}}
}
\author{Sepp Hochreiter}
\examples{


\dontrun{

###here an example of the the automatically generated pipeline
### with: shiftSize=5000,segmentSize=10000,fileName="filename"


#####define segments, overlap, filename #######
shiftSize <- 5000
segmentSize <- 10000
fileName="filename" # without type
haplotypes <- TRUE
dosage <- FALSE

#####load library#######
library(hapFabia)

#####convert from .vcf to _mat.txt#######
vcftoFABIA(fileName=fileName)

#####copy haplotype, genotype, or dosage matrix to matrix#######
if (haplotypes) {
    file.copy(paste(fileName,"_matH.txt",sep=""), paste(fileName,"_mat.txt",sep=""))
} else {
    if (dosage) {
        file.copy(paste(fileName,"_matD.txt",sep=""), paste(fileName,"_mat.txt",sep=""))
    } else {
        file.copy(paste(fileName,"_matG.txt",sep=""), paste(fileName,"_mat.txt",sep=""))
    }
}

#####split/ generate segments#######
split_sparse_matrix(fileName=fileName,segmentSize=segmentSize,
shiftSize=shiftSize,annotation=TRUE)

#####compute how many segments we have#######
ina <- as.numeric(readLines(paste(fileName,"_mat.txt",sep=""),n=2))
noSNVs <- ina[2]
over <- segmentSize\%/\%shiftSize
N1 <- noSNVs\%/\%shiftSize
endRunA <- (N1-over+2)

#####analyze each segment#######
#####may be done by parallel runs#######
iterateSegments(startRun=1,endRun=endRunA,shift=shiftSize,
segmentSize=segmentSize,fileName=fileName,individuals=0,
upperBP=0.05,p=10,iter=40,alpha=0.03,cyc=50,haploClusterLength=50,
Lt = 0.1,Zt = 0.2,thresCount=1e-5,mintagSNVsFactor=3/4,
pMAF=0.035,haplotypes=haplotypes,cut=0.8,procMinIndivids=0.1,thresPrune=1e-3,
simv="minD",minTagSNVs=6,minIndivid=2,avSNVsDist=100,SNVclusterLength=100)

#####identify duplicates#######
identifyDuplicates(fileName=fileName,startRun=1,endRun=endRunA,
shift=shiftSize,segmentSize=segmentSize)

#####analyze results; parallel#######
anaRes <- analyzeHaploClusters(fileName=fileName,startRun=1,endRun=endRunA,
shift=shiftSize,segmentSize=segmentSize)
print("Number haplotype clusters:")
print(anaRes$nohaploClusters)
print("Statistics on haplotye cluster length in SNVs (all SNVs in the haplotype cluster):")
print(anaRes$avhaploClusterLengthSNVS)
print("Statistics on haplotye cluster length in bp:")
print(anaRes$avhaploClusterLengthS)
print("Statistics on number of individuals belonging to haplotye clusters:")
print(anaRes$avnoIndividS)
print("Statistics on number of tagSNVs of haplotye clusters:")
print(anaRes$avnoTagSNVsS)
print("Statistics on MAF of tagSNVs of haplotye clusters:")
print(anaRes$avnoFreqS)
print("Statistics on MAF within the group of tagSNVs of haplotye clusters:")
print(anaRes$avnoGroupFreqS)
print("Statistics on number of changes between major and minor allele frequency:")
print(anaRes$avnotagSNVChangeS)
print("Statistics on number of tagSNVs per individual of a haplotype cluster:")
print(anaRes$avnotagSNVsPerIndividualS)
print("Statistics on number of individuals that have the minor allele of tagSNVs:")
print(anaRes$avnoindividualPerTagSNVS)

#####load result for segment 50#######
posAll <- 50 # (50-1)*5000 = 245000: segment 245000 to 255000
start <- (posAll-1)*shiftSize
end <- start + segmentSize
pRange <- paste("_",format(start,scientific=FALSE),"_",
format(end,scientific=FALSE),sep="")
load(file=paste(fileName,pRange,"_resAnno",".Rda",sep=""))
haploClusterList <- resHapFabia$mergedHaploClusterList # $

summary(haploClusterList)
#####plot haplotype clusters in segment 50#######
plot(haploClusterList,filename=paste(fileName,pRange,"_mat",sep=""))
   ##attention: filename without type ".txt"

#####plot the first haplotype cluster in segment 50#######

haploCluster <- haploClusterList[[1]]
plot(haploCluster,filename=paste(fileName,pRange,"_mat",sep=""))
   ##attention: filename without type ".txt"

}

#Work in a temporary directory.

old_dir <- getwd()
setwd(tempdir())


# Load data and write to vcf file.
data(chr1ASW1000G)
write(chr1ASW1000G,file="chr1ASW1000G.vcf")

#Create the analysis pipeline for haplotype data (1000Genomes)
makePipelineFile(fileName="chr1ASW1000G",shiftSize=500,segmentSize=1000,haplotypes=TRUE)

source("pipeline.R")

# Following files are produced:
list.files(pattern="chr1")



# Next we load segment 5 and there the first and second haplotype cluster
posAll <- 5
start <- (posAll-1)*shiftSize
end <- start + segmentSize
pRange <- paste("_",format(start,scientific=FALSE),"_",format(end,scientific=FALSE),sep="")
load(file=paste(fileName,pRange,"_resAnno",".Rda",sep=""))
haploClusterList <- resHapFabia$mergedHaploClusterList
summary(haploClusterList)
haploCluster1 <- haploClusterList[[1]]
summary(haploCluster1)
haploCluster2 <- haploClusterList[[2]]
summary(haploCluster2)




#Plot the first haplotype cluster in segment 5
plot(haploCluster1,filename=paste(fileName,pRange,"_mat",sep=""))


#Plot the second haplotype cluster in segment 5
plot(haploCluster2,filename=paste(fileName,pRange,"_mat",sep=""))

setwd(old_dir)


}
\references{

S. Hochreiter et al.,
\sQuote{FABIA: Factor Analysis for Bicluster Acquisition},
Bioinformatics 26(12):1520-1527, 2010.

}
\keyword{models,multivariate,cluster}
\concept{genetics,haplotype,identity by descent,bicluster,next generation sequencing,genotype,single nucleotide polymorphism,single nucleotide variation,rare variants,rare SNPs, rare SNVs,rare haplotype clusters,short haplotype clusters}
